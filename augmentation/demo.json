{
    "IMDB" : {
        "prompt" :"Given an example as a binary sentiment classification dataset consisting of texts from a movie review and labels of each text, perform the task of classifying if the text is positive or negative. Create at least two new data like the examples provided without numbering. Please ensure the text has more than 4 sentences.\n\nExample dataset :\n\n",
        "delete" :"IMDB is a large movie review dataset, a dataset for binary sentiment classification. The data should be evaluated to ensure that it has appropriate labels for binary sentiment classification and meets criteria such as clarity, grammatical accuracy, and contextual accuracy. If the data is found to be inappropriate, it should be deleted. Write a one-sentence comment about the evaluation, pre-add a “reason” key, and pre-add a “status” key to indicate “delete” if the data should be deleted or “appropriate” if the data is appropriate. The output only requires “reason” and “status” and must be in JSON format.\n\nInput data:\n\n",
        "example" : "text: I watched the movie in a preview and I really loved it. The cast is excellent and the plot is sometimes absolutely hilarious. Another highlight of the movie is definitely the music, which hopefully will be released soon. I recommend it to everyone who likes the British humour and especially to all musicians. Go and see. It's great.\nlabel: positive\n\ntext: I saw this movie not knowing anything about it before hand. The plot was terrible with large gaps of information missing. The movie didn't have the 'battle of wits' feel to me. The actors just spewed out mouthful's of nonsense, at times causing me to gnash my teeth in agony as they droned on and on. The plot was predictable except for the stomach sickening homo erotic scene at the end (I'm not homophobic but made me physically sick to my stomach), even the ending was predictable. And you could tell the detective was Jude Law in a costume, everything from the fake accent, terrible dental work, costume shop facial hair, everything pointed to it being a disguise. The whole movie just felt like wasted time out of my life. This movie had the feel of a puppet show with Jude Law and Michael Caine as puppets and the house as the window to view the show, really boooring in my opinion.\nlabel: negative"
    },"RTE" : {
        "prompt" : "In the GLUE benchmark, the Recognizing Textual Entailment (RTE) task evaluates models' capability to determine whether a hypothesis can be logically inferred from a given premise. Below are examples from the RTE task, showcasing both entailment and non-entailment relationships. Generate at least one new example for each label.\n\nExample dataset :\n\n",
        "delete" : "In the GLUE benchmark, the Recognizing Textual Entailment (RTE) task evaluates models' capability to determine whether a hypothesis can be logically inferred from a given premise. Below are data from the RTE task. Each dataset entry should be evaluated to ensure that it meets the following criteria: clarity, variety, grammatical correctness, and contextual correctness. If the data is found to be inappropriate, it should be deleted. Add a “status” key to the dictionary, labeling it “Delete” if the data should be deleted, or “Appropriate” if the data is appropriate. The output only requires “reason” and “status” and must be in JSON format.\n\ninput data :\n\n",
        "example" : "Premise: Mr. Balasingham will return to his London home and then move on to Sri Lanka in early October to consult with LTTE leader Vilupillai Prabhakaran, diplomats said.\nHypothesis: Vilupillai Prabhakaran is a diplomat.\nLabel: not entailment\n\nPremise: Springsteen performed 27 songs Monday night, including most of the 12 new songs from his latest release, "Devils and Dust", which was recorded without the E Street Band.\nHypothesis: Springsteen introduced some of the 12 new songs off his latest release, 'Devils andDust', which was recorded without the E Street Band.\nLabel: entailment"
    },"WNLI" : {
        "prompt" :"The Winograd Schema Challenge assesses a system's capability to determine whether a sentence or clause beginning with a pronoun accurately refers to the entity mentioned earlier in the text. This evaluation focuses on the system's proficiency in interpreting pronouns within the given context. Below are example datasets illustrating this concept. Refer to each example to generate at least two data.\n\nExample dataset :\n\n",
        "delete" :"The Winograd Schema Challenge assesses a system's capability to determine whether a sentence or clause beginning with a pronoun accurately refers to the entity mentioned earlier in the text. This evaluation focuses on the system's proficiency in interpreting pronouns within the given context. Below are example datasets illustrating this concept. Each dataset entry should be evaluated to ensure that it meets the following criteria: clarity, variety, grammatical correctness, and contextual correctness. If the data is found to be inappropriate, it should be deleted. Add a “status” key to the dictionary, labeling it “Delete” if the data should be deleted, or “Appropriate” if the data is appropriate. The output only requires “reason” and “status” and must be in JSON format.\n\ninput data :\n\n",
        "example" : "Premise: Always before, Larry had helped Dad with his work. But he could not help him now, for Dad said that his boss at the railroad company would not want anyone but him to work in the office.\nHypothesis: Larry's boss at the railroad company would not want anyone but him to work in the office.\nLabel: not entailment\n\nPremise: Even before they reached town, they could hear a sound like corn popping. Dora asked what it was, and Dad said it was firecrackers.\nHypothesis: Dora asked what the sound was.\nLabel: entailment"
    },"BOOLQ" : {
        "prompt" :"The following are examples of datasets used for binary classification tasks, specifically determining whether the answer to a given question is true or false based on information provided in a passage. Each dataset contains a question, a passage, and an answer. Refer to the example and create two new data. Please vary the topics of your questions to people, regions, places, science, common sense, life, society, etc. Make your questions as specific as possible. Avoid questions about famous topics or well-known places, people, animals, and regions. True or false labels must always match the facts. \n\nExample dataset :\n\n",
        "delete" :"BoolQ is a large dataset for binary classification tasks, specifically determining whether the answer to a given question is true or false based on information provided in a passage. The data should be evaluated to ensure that it has appropriate labels for binary classification and meets criteria such as clarity, grammatical accuracy, and contextual accuracy. Based on the given passage, the questions and answers must absolutely match the facts. If the data is found to be inappropriate, it should be deleted. Write a one-sentence comment about the evaluation, pre-add a “reason” key, and pre-add a “status” key to indicate “delete” if the data should be deleted or “appropriate” if the data is appropriate. The output only requires “reason” and “status” and must be in JSON format.\n\nInput data:\n\n",
        "example" : "Question: are there any original members of the little river band\nPassage: Little River Band have undergone numerous personnel changes, with over 30 members since their formation. None of the musicians now performing as Little River Band are original members, nor did they contribute to the success the band had in the 1970s. In the 1980s, members included John Farnham, David Hirschfelder, Stephen Housden, Wayne Nelson and Steve Prestwich. Currently the line-up is Nelson with Rich Herring, Greg Hind, Chris Marion and Ryan Ricks. Two former members have died, Barry Sullivan in October 2003 (aged 57) and Steve Prestwich in January 2011 (aged 56).\nAnswer: False\n\nQuestion: is the department of education a government agency\nPassage: The Department for Education (DfE) is a department of Her Majesty's Government responsible for child protection, education (compulsory, further and higher education), apprenticeships and wider skills in England. The DfE is also responsible for women and equalities policy.\nAnswer: True"
    }
}